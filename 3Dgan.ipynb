{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47075e6-93c9-497c-8a61-7bb9e7f5d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/MRI-inpainting-project/data_scripts') # path to datasets.py dir\n",
    "\n",
    "from datasets import TrainPatchesDataset, HealthyMRIDataset, PathologicalMRIDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8c6fcf-60a6-4af3-9e7e-911ad4377e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches = TrainPatchesDataset(\"/workspace/MRI-inpainting-project/data/train_patches_v3\")\n",
    "healthy_data = HealthyMRIDataset('/workspace/MRI-inpainting-project/data/healthy_mri_C_00/healthy_mri_t1',\n",
    "                                 '/workspace/MRI-inpainting-project/data/healthy_mri_C_00/healthy_masks_t1/sphere_masks/masks',\n",
    "                                 '/workspace/MRI-inpainting-project/data/healthy_mri_C_00/healthy_masks_t1/sphere_masks/patch_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da8b194-88af-4f40-bd5d-6317990efd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [0/20], Loss D: 1.3914, Loss G: 0.7639\n",
      "Epoch [1/5], Step [10/20], Loss D: 1.2631, Loss G: 0.6328\n",
      "Epoch [2/5], Step [0/20], Loss D: 1.2852, Loss G: 0.7212\n",
      "Epoch [2/5], Step [10/20], Loss D: 1.2383, Loss G: 0.8354\n",
      "Epoch [3/5], Step [0/20], Loss D: 1.0589, Loss G: 0.8707\n",
      "Epoch [3/5], Step [10/20], Loss D: 1.1100, Loss G: 0.7930\n",
      "Epoch [4/5], Step [0/20], Loss D: 0.9770, Loss G: 1.0188\n",
      "Epoch [4/5], Step [10/20], Loss D: 0.8715, Loss G: 0.9529\n",
      "Epoch [5/5], Step [0/20], Loss D: 0.7503, Loss G: 1.1693\n",
      "Epoch [5/5], Step [10/20], Loss D: 0.6600, Loss G: 1.2262\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # Input channels: noise (1) + condition image (1) = 2\n",
    "        self.main = nn.Sequential(\n",
    "            # Encoder part\n",
    "            nn.Conv3d(2, 64, kernel_size=4, stride=2, padding=1),  # Output: [64, 20, 20, 20]\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1),  # Output: [128, 10, 10, 10]\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv3d(128, 256, kernel_size=4, stride=2, padding=1),  # Output: [256, 5, 5, 5]\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(True),\n",
    "            # Decoder part\n",
    "            nn.ConvTranspose3d(256, 128, kernel_size=4, stride=2, padding=1),  # Output: [128, 10, 10, 10]\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1),  # Output: [64, 20, 20, 20]\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose3d(64, 1, kernel_size=4, stride=2, padding=1),  # Output: [1, 40, 40, 40]\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "        \n",
    "    def forward(self, noise, condition):\n",
    "        x = torch.cat([noise, condition], dim=1) \n",
    "        mask = self.main(x)\n",
    "        return mask  \n",
    "\n",
    "# Define the Discriminator class\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv3d(1, 4, kernel_size=4, stride=2, padding=1),  # Output: [64, 20, 20, 20]\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(4, 4, kernel_size=4, stride=2, padding=1),  # Output: [128, 10, 10, 10]\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(4, 4, kernel_size=4, stride=2, padding=1),  # Output: [256, 5, 5, 5]\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv3d(4, 1, kernel_size=5),  # Output: [1, 1, 1, 1]\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "        \n",
    "    def forward(self, masked_image):\n",
    "        output = self.main(masked_image)\n",
    "        return output.view(-1) \n",
    "\n",
    "\n",
    "class MRI3DDataset(Dataset):\n",
    "    def __init__(self, num_samples, image_shape):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        mri = healthy_data[idx]['mri']\n",
    "        patch_mask = healthy_data[idx]['patch_mask']\n",
    "\n",
    "        condition_image = torch.from_numpy(mri[patch_mask > 0].reshape(40, 40, 40)).unsqueeze(0).float()\n",
    "        real_masked_image = torch.from_numpy(train_patches[idx]['patch'] * (1-train_patches[idx]['mask'])).unsqueeze(0).float()\n",
    "\n",
    "        \n",
    "        return {'condition_image': condition_image, 'real_masked_image': real_masked_image}\n",
    "\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 4  \n",
    "image_shape = (40, 40, 40)  \n",
    "noise_shape = (1, *image_shape)  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(D.parameters(), lr=0.0002)\n",
    "optimizerG = optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "dataset = MRI3DDataset(num_samples=77, image_shape=image_shape)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader):\n",
    "        ############################\n",
    "        # Update Discriminator\n",
    "        ############################\n",
    "        D.zero_grad()\n",
    "        \n",
    "        condition_image = data['condition_image'].to(device)  \n",
    "        real_masked_image = data['real_masked_image'].to(device)\n",
    "        batch_size = condition_image.size(0)\n",
    "        real_labels = torch.ones(batch_size, device=device)\n",
    "        \n",
    "        output = D(real_masked_image)\n",
    "        lossD_real = criterion(output, real_labels)\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            lossD_real.backward()\n",
    "        \n",
    "        noise = torch.randn(batch_size, *noise_shape, device=device)\n",
    "        fake_mask = G(noise, condition_image)\n",
    "        fake_masked_image = condition_image * (1 - (fake_mask > 0.5).float())\n",
    "        fake_labels = torch.zeros(batch_size, device=device)\n",
    "        \n",
    "        output = D(fake_masked_image.detach())\n",
    "        lossD_fake = criterion(output, fake_labels)\n",
    "\n",
    "        if i % 3 == 0:\n",
    "            lossD_fake.backward()\n",
    "            optimizerD.step()\n",
    "        \n",
    "        ############################\n",
    "        # Update Generator\n",
    "        ############################\n",
    "        G.zero_grad()\n",
    "        output = D(fake_masked_image)\n",
    "        \n",
    "        lossG = criterion(output, real_labels)\n",
    "        lossG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i}/{len(dataloader)}], \"\n",
    "                  f\"Loss D: {(lossD_real + lossD_fake).item():.4f}, Loss G: {lossG.item():.4f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19956eae-0fee-4a2e-a638-4b204d060c67",
   "metadata": {},
   "source": [
    "## Generating mask example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4285b026-b624-4280-ba5e-8500b2ac572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "mri, mask, patch_mask = healthy_data[idx]['mri'], healthy_data[idx]['mask'], healthy_data[idx]['patch_mask']\n",
    "patch = torch.from_numpy(mri[patch_mask > 0].reshape(40, 40, 40)).float().unsqueeze(0).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135a53a6-7114-4fae-a54d-1e270f73c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "noise = torch.randn(1, *noise_shape, device=device)\n",
    "fake_mask = G(noise, patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40c8c38-72af-4fc9-88a2-49fb9004f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mask = fake_mask.to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab0bb00-d167-4add-945c-eda617e4be84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1ff6041850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fake_mask.squeeze()[:, :, 0] > 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
